"""
AIå†…å®¹åˆ†æå™¨ - ä½¿ç”¨OpenAIå…¼å®¹æ¥å£
"""
import json
from typing import Dict, Any, List, Optional
from openai import OpenAI
import logging
from datetime import datetime

logger = logging.getLogger(__name__)


class AIAnalyzer:
    """AIå†…å®¹åˆ†æå™¨"""

    def __init__(
        self,
        api_key: str,
        base_url: str = "https://api.openai.com/v1",
        model: str = "gpt-4-turbo-preview",
        embedding_model: str = "text-embedding-3-small",
    ):
        try:
            # åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯ï¼Œåªä¼ é€’å¿…éœ€å‚æ•°
            self.client = OpenAI(
                api_key=api_key,
                base_url=base_url,
                timeout=60.0,
                max_retries=2,
            )
            self.model = model
            self.embedding_model = embedding_model
            logger.info(f"âœ… AIåˆ†æå™¨åˆå§‹åŒ–æˆåŠŸ (model: {model})")
        except Exception as e:
            logger.error(f"âŒ AIåˆ†æå™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            raise

    def analyze_article(self, article: Dict[str, Any]) -> Dict[str, Any]:
        """
        åˆ†ææ–‡ç« ï¼Œç”Ÿæˆæ€»ç»“å’Œæ ‡ç­¾

        Args:
            article: æ–‡ç« å­—å…¸

        Returns:
            åˆ†æç»“æœ
        """
        try:
            logger.info(f"ğŸ¤– æ­£åœ¨åˆ†ææ–‡ç« : {article['title'][:50]}...")

            # å‡†å¤‡åˆ†æå†…å®¹
            content = self._prepare_content(article)

            # è°ƒç”¨LLMåˆ†æ
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": self._get_system_prompt(),
                    },
                    {
                        "role": "user",
                        "content": self._get_user_prompt(content),
                    },
                ],
                temperature=0.3,
                response_format={"type": "json_object"},
            )

            # è§£æç»“æœ
            result_text = response.choices[0].message.content
            result = json.loads(result_text)

            logger.info(f"âœ… åˆ†æå®Œæˆ: {result.get('summary', '')[:50]}...")
            return result

        except Exception as e:
            logger.error(f"âŒ AIåˆ†æå¤±è´¥: {e}")
            return self._get_default_analysis()

    def _prepare_content(self, article: Dict[str, Any]) -> str:
        """å‡†å¤‡å¾…åˆ†æçš„å†…å®¹"""
        title = article.get("title", "")
        content = article.get("content", "")
        source = article.get("source", "")

        # å¯¹äºå®Œæ•´å†…å®¹ï¼Œä½¿ç”¨æ›´å¤§çš„é•¿åº¦é™åˆ¶ï¼ˆ8000å­—ç¬¦ï¼‰
        # å¦‚æœå†…å®¹å¤ªé•¿ï¼Œæˆªå–å‰8000å­—ç¬¦ï¼Œä½†ä¿ç•™å®Œæ•´å¥å­
        max_content_length = 8000
        if len(content) > max_content_length:
            # å°è¯•åœ¨å¥å­è¾¹ç•Œæˆªæ–­
            truncated = content[:max_content_length]
            last_period = truncated.rfind('.')
            last_newline = truncated.rfind('\n')
            cut_point = max(last_period, last_newline)
            if cut_point > max_content_length * 0.8:  # å¦‚æœæˆªæ–­ç‚¹ä¸å¤ªé å‰
                content = truncated[:cut_point + 1] + "..."
            else:
                content = truncated + "..."

        return f"""æ ‡é¢˜: {title}
æ¥æº: {source}
å‘å¸ƒæ—¶é—´: {article.get('published_at', 'Unknown')}
æ­£æ–‡: {content}"""

    def _get_system_prompt(self) -> str:
        """è·å–ç³»ç»Ÿæç¤ºè¯"""
        return """ä½ æ˜¯ä¸€ä½AIç ”ç©¶é¢†åŸŸçš„ä¸“å®¶åˆ†æå¸ˆã€‚ä½ çš„ä»»åŠ¡æ˜¯åˆ†æAIç›¸å…³çš„æ–‡ç« ã€è®ºæ–‡å’Œæ–°é—»ï¼Œæä¾›é«˜è´¨é‡çš„ç»“æ„åŒ–åˆ†æã€‚

**é‡è¦è¦æ±‚ï¼šæ‰€æœ‰è¾“å‡ºå†…å®¹å¿…é¡»ä½¿ç”¨ä¸­æ–‡ï¼ˆç®€ä½“ä¸­æ–‡ï¼‰ã€‚**

è¯·æŒ‰ç…§JSONæ ¼å¼è¿”å›åˆ†æç»“æœï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š
{
  "summary": "3-5å¥è¯çš„æ ¸å¿ƒæ€»ç»“ï¼Œçªå‡ºæœ€é‡è¦çš„ä¿¡æ¯ï¼ˆå¿…é¡»ç”¨ä¸­æ–‡ï¼‰",
  "key_points": ["å…³é”®ç‚¹1", "å…³é”®ç‚¹2", "å…³é”®ç‚¹3", ...]ï¼ˆå¿…é¡»ç”¨ä¸­æ–‡ï¼‰,
  "topics": ["ä¸»é¢˜1", "ä¸»é¢˜2", ...]ï¼ˆå¯ä»¥ç”¨è‹±æ–‡æŠ€æœ¯æœ¯è¯­ï¼Œä½†å°½é‡ç”¨ä¸­æ–‡ï¼‰,
  "importance": "high/medium/low",
  "target_audience": "researcher/engineer/general/entrepreneur/investor",
  "tags": ["æ ‡ç­¾1", "æ ‡ç­¾2", ...]ï¼ˆå¯ä»¥ç”¨è‹±æ–‡æŠ€æœ¯æœ¯è¯­ï¼Œä½†å°½é‡ç”¨ä¸­æ–‡ï¼‰,
  "technical_depth": "introductory/intermediate/advanced",
  "related_fields": ["ç›¸å…³é¢†åŸŸ1", "ç›¸å…³é¢†åŸŸ2", ...]ï¼ˆå¿…é¡»ç”¨ä¸­æ–‡ï¼‰
}

è¯„ä¼°æ ‡å‡†ï¼š
- importance (high): é‡å¤§çªç ´ã€æ–°æ¨¡å‹å‘å¸ƒã€ä¸šç•Œé‡è¦åŠ¨æ€ã€é¡¶çº§ä¼šè®®è®ºæ–‡
- importance (medium): æœ‰ä»·å€¼çš„ç ”ç©¶ã€æŠ€æœ¯æ”¹è¿›ã€è¡Œä¸šæ–°é—»
- importance (low): ä¸€èˆ¬æ€§æŠ¥é“ã€ç®€å•ä»‹ç»

- target_audience:
  - researcher: é¢å‘å­¦æœ¯ç ”ç©¶è€…ï¼ŒåŒ…å«è¯¦ç»†æŠ€æœ¯ç»†èŠ‚
  - engineer: é¢å‘å·¥ç¨‹å¸ˆï¼ŒåŒ…å«å®ç°ç»†èŠ‚å’Œä»£ç 
  - general: é¢å‘å¤§ä¼—ï¼Œé€šä¿—æ˜“æ‡‚
  - entrepreneur: é¢å‘åˆ›ä¸šè€…ï¼ŒåŒ…å«å•†ä¸šåº”ç”¨
  - investor: é¢å‘æŠ•èµ„è€…ï¼ŒåŒ…å«å¸‚åœºå‰æ™¯

- topics: å¤§ä¸»é¢˜ï¼Œå¦‚ ["è‡ªç„¶è¯­è¨€å¤„ç†", "è®¡ç®—æœºè§†è§‰", "å¼ºåŒ–å­¦ä¹ ", "AIå®‰å…¨"]

- tags: å…·ä½“æ ‡ç­¾ï¼Œå¦‚ ["GPT-4", "Transformer", "å¾®è°ƒ", "å¤§è¯­è¨€æ¨¡å‹"]

**è¯·ç¡®ä¿æ‰€æœ‰æ–‡æœ¬å†…å®¹ï¼ˆsummaryã€key_pointsã€related_fieldsç­‰ï¼‰éƒ½ä½¿ç”¨ä¸­æ–‡è¾“å‡ºã€‚æŠ€æœ¯æœ¯è¯­å¯ä»¥ä¿ç•™è‹±æ–‡ï¼Œä½†æè¿°æ€§æ–‡å­—å¿…é¡»ç”¨ä¸­æ–‡ã€‚**"""

    def _get_user_prompt(self, content: str) -> str:
        """è·å–ç”¨æˆ·æç¤ºè¯"""
        return f"""è¯·åˆ†æä»¥ä¸‹AIç›¸å…³å†…å®¹ï¼Œè¿”å›ç»“æ„åŒ–çš„JSONæ ¼å¼åˆ†æï¼š

{content}

**é‡è¦ï¼šè¯·ä½¿ç”¨ä¸­æ–‡ï¼ˆç®€ä½“ä¸­æ–‡ï¼‰è¾“å‡ºæ‰€æœ‰æ–‡æœ¬å†…å®¹ï¼ŒåŒ…æ‹¬summaryã€key_pointsã€related_fieldsç­‰å­—æ®µã€‚æŠ€æœ¯æœ¯è¯­å¯ä»¥ä¿ç•™è‹±æ–‡ï¼Œä½†æè¿°æ€§æ–‡å­—å¿…é¡»ç”¨ä¸­æ–‡ã€‚**

è¯·æŒ‰ç…§è¦æ±‚çš„JSONæ ¼å¼è¿”å›åˆ†æç»“æœã€‚"""

    def _get_default_analysis(self) -> Dict[str, Any]:
        """è·å–é»˜è®¤åˆ†æç»“æœï¼ˆåˆ†æå¤±è´¥æ—¶ä½¿ç”¨ï¼‰"""
        return {
            "summary": "AIåˆ†ææš‚æ—¶ä¸å¯ç”¨",
            "key_points": [],
            "topics": [],
            "importance": "low",
            "target_audience": "general",
            "tags": [],
            "technical_depth": "introductory",
            "related_fields": [],
        }

    def batch_analyze(self, articles: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        æ‰¹é‡åˆ†ææ–‡ç« 

        Args:
            articles: æ–‡ç« åˆ—è¡¨

        Returns:
            åˆ†æç»“æœåˆ—è¡¨
        """
        results = []
        total = len(articles)

        for i, article in enumerate(articles, 1):
            logger.info(f"ğŸ¤– åˆ†æè¿›åº¦: {i}/{total}")
            result = self.analyze_article(article)
            results.append(result)

        return results

    def generate_daily_summary(self, articles: List[Dict[str, Any]], max_count: int = 10) -> str:
        """
        ç”Ÿæˆæ¯æ—¥æ‘˜è¦

        Args:
            articles: æ–‡ç« åˆ—è¡¨
            max_count: æœ€å¤šåŒ…å«æ–‡ç« æ•°

        Returns:
            æ‘˜è¦æ–‡æœ¬
        """
        try:
            logger.info(f"ğŸ“ æ­£åœ¨ç”Ÿæˆæ¯æ—¥æ‘˜è¦...")

            # ç­›é€‰é‡è¦æ–‡ç« 
            important_articles = [a for a in articles if a.get("importance") in ["high", "medium"]][:max_count]

            if not important_articles:
                return "ä»Šæ—¥æš‚æ— é‡è¦AIèµ„è®¯"

            # å‡†å¤‡æ‘˜è¦å†…å®¹
            articles_text = ""
            for i, article in enumerate(important_articles, 1):
                articles_text += f"""
{i}. æ ‡é¢˜: {article.get('title', 'Unknown')}
   æ¥æº: {article.get('source', 'Unknown')}
   æ€»ç»“: {article.get('summary', article.get('content', '')[:200])}
   é‡è¦æ€§: {article.get('importance', 'low')}
   ä¸»é¢˜: {', '.join(article.get('topics', []))}
"""

            # è°ƒç”¨LLMç”Ÿæˆæ‘˜è¦
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„AIèµ„è®¯ç¼–è¾‘ã€‚è¯·æ ¹æ®æä¾›çš„é‡è¦AIèµ„è®¯ï¼Œç”Ÿæˆä¸€ä»½ç®€æ´ã€æœ‰ä»·å€¼çš„æ¯æ—¥æ‘˜è¦ã€‚

æ‘˜è¦æ ¼å¼è¦æ±‚ï¼š
1. ä½¿ç”¨Markdownæ ¼å¼
2. å¼€å¤´ç»™å‡ºä»Šæ—¥æ ¸å¿ƒè¦ç‚¹ï¼ˆ3-5æ¡ï¼‰
3. æŒ‰ä¸»é¢˜åˆ†ç±»å±•ç¤ºé‡è¦èµ„è®¯
4. æ¯æ¡èµ„è®¯åŒ…å«æ ‡é¢˜ã€æ¥æºã€æ ¸å¿ƒä»·å€¼
5. è¯­è¨€ç®€æ´ä¸“ä¸šï¼Œé€‚åˆå¿«é€Ÿé˜…è¯»
6. ç»“å°¾å¯ä»¥ç»™å‡ºè¶‹åŠ¿æ´å¯Ÿï¼ˆå¦‚æœæœ‰ï¼‰

ä¿æŒæ‘˜è¦åœ¨800å­—ä»¥å†…ã€‚""",
                    },
                    {
                        "role": "user",
                        "content": f"""è¯·ä¸ºä»¥ä¸‹AIèµ„è®¯ç”Ÿæˆæ¯æ—¥æ‘˜è¦ï¼š

{articles_text}

è¯·ç”Ÿæˆä¸€ä»½ä¸“ä¸šçš„æ¯æ—¥æ‘˜è¦ã€‚""",
                    },
                ],
                temperature=0.5,
                max_tokens=2000,
            )

            summary = response.choices[0].message.content
            logger.info("âœ… æ¯æ—¥æ‘˜è¦ç”Ÿæˆå®Œæˆ")
            return summary

        except Exception as e:
            logger.error(f"âŒ ç”Ÿæˆæ¯æ—¥æ‘˜è¦å¤±è´¥: {e}")
            return f"æ¯æ—¥æ‘˜è¦ç”Ÿæˆå¤±è´¥: {str(e)}"

    def get_embedding(self, text: str) -> List[float]:
        """
        è·å–æ–‡æœ¬çš„å‘é‡è¡¨ç¤º

        Args:
            text: è¾“å…¥æ–‡æœ¬

        Returns:
            å‘é‡åˆ—è¡¨
        """
        try:
            response = self.client.embeddings.create(model=self.embedding_model, input=text)
            return response.data[0].embedding
        except Exception as e:
            logger.error(f"âŒ è·å–å‘é‡å¤±è´¥: {e}")
            return []
