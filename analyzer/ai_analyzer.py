"""
AIå†…å®¹åˆ†æå™¨ - ä½¿ç”¨OpenAIå…¼å®¹æ¥å£
"""
import json
from typing import Dict, Any, List, Optional
from openai import OpenAI
import logging
from datetime import datetime

logger = logging.getLogger(__name__)


class AIAnalyzer:
    """AIå†…å®¹åˆ†æå™¨"""

    def __init__(
        self,
        api_key: str,
        base_url: str = "https://api.openai.com/v1",
        model: str = "gpt-4-turbo-preview",
        embedding_model: str = "text-embedding-3-small",
    ):
        self.client = OpenAI(api_key=api_key, base_url=base_url)
        self.model = model
        self.embedding_model = embedding_model

    def analyze_article(self, article: Dict[str, Any]) -> Dict[str, Any]:
        """
        åˆ†ææ–‡ç« ï¼Œç”Ÿæˆæ€»ç»“å’Œæ ‡ç­¾

        Args:
            article: æ–‡ç« å­—å…¸

        Returns:
            åˆ†æç»“æœ
        """
        try:
            logger.info(f"ğŸ¤– æ­£åœ¨åˆ†ææ–‡ç« : {article['title'][:50]}...")

            # å‡†å¤‡åˆ†æå†…å®¹
            content = self._prepare_content(article)

            # è°ƒç”¨LLMåˆ†æ
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": self._get_system_prompt(),
                    },
                    {
                        "role": "user",
                        "content": self._get_user_prompt(content),
                    },
                ],
                temperature=0.3,
                response_format={"type": "json_object"},
            )

            # è§£æç»“æœ
            result_text = response.choices[0].message.content
            result = json.loads(result_text)

            logger.info(f"âœ… åˆ†æå®Œæˆ: {result.get('summary', '')[:50]}...")
            return result

        except Exception as e:
            logger.error(f"âŒ AIåˆ†æå¤±è´¥: {e}")
            return self._get_default_analysis()

    def _prepare_content(self, article: Dict[str, Any]) -> str:
        """å‡†å¤‡å¾…åˆ†æçš„å†…å®¹"""
        title = article.get("title", "")
        content = article.get("content", "")
        source = article.get("source", "")

        # é™åˆ¶å†…å®¹é•¿åº¦
        max_content_length = 4000
        if len(content) > max_content_length:
            content = content[:max_content_length] + "..."

        return f"""æ ‡é¢˜: {title}
æ¥æº: {source}
å‘å¸ƒæ—¶é—´: {article.get('published_at', 'Unknown')}
æ­£æ–‡: {content}"""

    def _get_system_prompt(self) -> str:
        """è·å–ç³»ç»Ÿæç¤ºè¯"""
        return """ä½ æ˜¯ä¸€ä½AIç ”ç©¶é¢†åŸŸçš„ä¸“å®¶åˆ†æå¸ˆã€‚ä½ çš„ä»»åŠ¡æ˜¯åˆ†æAIç›¸å…³çš„æ–‡ç« ã€è®ºæ–‡å’Œæ–°é—»ï¼Œæä¾›é«˜è´¨é‡çš„ç»“æ„åŒ–åˆ†æã€‚

è¯·æŒ‰ç…§JSONæ ¼å¼è¿”å›åˆ†æç»“æœï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š
{
  "summary": "3-5å¥è¯çš„æ ¸å¿ƒæ€»ç»“ï¼Œçªå‡ºæœ€é‡è¦çš„ä¿¡æ¯",
  "key_points": ["å…³é”®ç‚¹1", "å…³é”®ç‚¹2", "å…³é”®ç‚¹3", ...],
  "topics": ["ä¸»é¢˜1", "ä¸»é¢˜2", ...],
  "importance": "high/medium/low",
  "target_audience": "researcher/engineer/general/entrepreneur/investor",
  "tags": ["æ ‡ç­¾1", "æ ‡ç­¾2", ...],
  "technical_depth": "introductory/intermediate/advanced",
  "related_fields": ["ç›¸å…³é¢†åŸŸ1", "ç›¸å…³é¢†åŸŸ2", ...]
}

è¯„ä¼°æ ‡å‡†ï¼š
- importance (high): é‡å¤§çªç ´ã€æ–°æ¨¡å‹å‘å¸ƒã€ä¸šç•Œé‡è¦åŠ¨æ€ã€é¡¶çº§ä¼šè®®è®ºæ–‡
- importance (medium): æœ‰ä»·å€¼çš„ç ”ç©¶ã€æŠ€æœ¯æ”¹è¿›ã€è¡Œä¸šæ–°é—»
- importance (low): ä¸€èˆ¬æ€§æŠ¥é“ã€ç®€å•ä»‹ç»

- target_audience:
  - researcher: é¢å‘å­¦æœ¯ç ”ç©¶è€…ï¼ŒåŒ…å«è¯¦ç»†æŠ€æœ¯ç»†èŠ‚
  - engineer: é¢å‘å·¥ç¨‹å¸ˆï¼ŒåŒ…å«å®ç°ç»†èŠ‚å’Œä»£ç 
  - general: é¢å‘å¤§ä¼—ï¼Œé€šä¿—æ˜“æ‡‚
  - entrepreneur: é¢å‘åˆ›ä¸šè€…ï¼ŒåŒ…å«å•†ä¸šåº”ç”¨
  - investor: é¢å‘æŠ•èµ„è€…ï¼ŒåŒ…å«å¸‚åœºå‰æ™¯

- topics: å¤§ä¸»é¢˜ï¼Œå¦‚ ["NLP", "Computer Vision", "Reinforcement Learning", "AI Safety"]

- tags: å…·ä½“æ ‡ç­¾ï¼Œå¦‚ ["GPT-4", "Transformer", "Fine-tuning", "LLM"]

ç¡®ä¿åˆ†æå‡†ç¡®ã€ç®€æ´ã€æœ‰ä»·å€¼ã€‚"""

    def _get_user_prompt(self, content: str) -> str:
        """è·å–ç”¨æˆ·æç¤ºè¯"""
        return f"""è¯·åˆ†æä»¥ä¸‹AIç›¸å…³å†…å®¹ï¼Œè¿”å›ç»“æ„åŒ–çš„JSONæ ¼å¼åˆ†æï¼š

{content}

è¯·æŒ‰ç…§è¦æ±‚çš„JSONæ ¼å¼è¿”å›åˆ†æç»“æœã€‚"""

    def _get_default_analysis(self) -> Dict[str, Any]:
        """è·å–é»˜è®¤åˆ†æç»“æœï¼ˆåˆ†æå¤±è´¥æ—¶ä½¿ç”¨ï¼‰"""
        return {
            "summary": "AIåˆ†ææš‚æ—¶ä¸å¯ç”¨",
            "key_points": [],
            "topics": [],
            "importance": "low",
            "target_audience": "general",
            "tags": [],
            "technical_depth": "introductory",
            "related_fields": [],
        }

    def batch_analyze(self, articles: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        æ‰¹é‡åˆ†ææ–‡ç« 

        Args:
            articles: æ–‡ç« åˆ—è¡¨

        Returns:
            åˆ†æç»“æœåˆ—è¡¨
        """
        results = []
        total = len(articles)

        for i, article in enumerate(articles, 1):
            logger.info(f"ğŸ¤– åˆ†æè¿›åº¦: {i}/{total}")
            result = self.analyze_article(article)
            results.append(result)

        return results

    def generate_daily_summary(self, articles: List[Dict[str, Any]], max_count: int = 10) -> str:
        """
        ç”Ÿæˆæ¯æ—¥æ‘˜è¦

        Args:
            articles: æ–‡ç« åˆ—è¡¨
            max_count: æœ€å¤šåŒ…å«æ–‡ç« æ•°

        Returns:
            æ‘˜è¦æ–‡æœ¬
        """
        try:
            logger.info(f"ğŸ“ æ­£åœ¨ç”Ÿæˆæ¯æ—¥æ‘˜è¦...")

            # ç­›é€‰é‡è¦æ–‡ç« 
            important_articles = [a for a in articles if a.get("importance") in ["high", "medium"]][:max_count]

            if not important_articles:
                return "ä»Šæ—¥æš‚æ— é‡è¦AIèµ„è®¯"

            # å‡†å¤‡æ‘˜è¦å†…å®¹
            articles_text = ""
            for i, article in enumerate(important_articles, 1):
                articles_text += f"""
{i}. æ ‡é¢˜: {article.get('title', 'Unknown')}
   æ¥æº: {article.get('source', 'Unknown')}
   æ€»ç»“: {article.get('summary', article.get('content', '')[:200])}
   é‡è¦æ€§: {article.get('importance', 'low')}
   ä¸»é¢˜: {', '.join(article.get('topics', []))}
"""

            # è°ƒç”¨LLMç”Ÿæˆæ‘˜è¦
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„AIèµ„è®¯ç¼–è¾‘ã€‚è¯·æ ¹æ®æä¾›çš„é‡è¦AIèµ„è®¯ï¼Œç”Ÿæˆä¸€ä»½ç®€æ´ã€æœ‰ä»·å€¼çš„æ¯æ—¥æ‘˜è¦ã€‚

æ‘˜è¦æ ¼å¼è¦æ±‚ï¼š
1. ä½¿ç”¨Markdownæ ¼å¼
2. å¼€å¤´ç»™å‡ºä»Šæ—¥æ ¸å¿ƒè¦ç‚¹ï¼ˆ3-5æ¡ï¼‰
3. æŒ‰ä¸»é¢˜åˆ†ç±»å±•ç¤ºé‡è¦èµ„è®¯
4. æ¯æ¡èµ„è®¯åŒ…å«æ ‡é¢˜ã€æ¥æºã€æ ¸å¿ƒä»·å€¼
5. è¯­è¨€ç®€æ´ä¸“ä¸šï¼Œé€‚åˆå¿«é€Ÿé˜…è¯»
6. ç»“å°¾å¯ä»¥ç»™å‡ºè¶‹åŠ¿æ´å¯Ÿï¼ˆå¦‚æœæœ‰ï¼‰

ä¿æŒæ‘˜è¦åœ¨800å­—ä»¥å†…ã€‚""",
                    },
                    {
                        "role": "user",
                        "content": f"""è¯·ä¸ºä»¥ä¸‹AIèµ„è®¯ç”Ÿæˆæ¯æ—¥æ‘˜è¦ï¼š

{articles_text}

è¯·ç”Ÿæˆä¸€ä»½ä¸“ä¸šçš„æ¯æ—¥æ‘˜è¦ã€‚""",
                    },
                ],
                temperature=0.5,
                max_tokens=2000,
            )

            summary = response.choices[0].message.content
            logger.info("âœ… æ¯æ—¥æ‘˜è¦ç”Ÿæˆå®Œæˆ")
            return summary

        except Exception as e:
            logger.error(f"âŒ ç”Ÿæˆæ¯æ—¥æ‘˜è¦å¤±è´¥: {e}")
            return f"æ¯æ—¥æ‘˜è¦ç”Ÿæˆå¤±è´¥: {str(e)}"

    def get_embedding(self, text: str) -> List[float]:
        """
        è·å–æ–‡æœ¬çš„å‘é‡è¡¨ç¤º

        Args:
            text: è¾“å…¥æ–‡æœ¬

        Returns:
            å‘é‡åˆ—è¡¨
        """
        try:
            response = self.client.embeddings.create(model=self.embedding_model, input=text)
            return response.data[0].embedding
        except Exception as e:
            logger.error(f"âŒ è·å–å‘é‡å¤±è´¥: {e}")
            return []
