"""
æ–‡ç« æ€»ç»“ç”Ÿæˆå™¨
ç”¨äºç”Ÿæˆæ¯æ—¥å’Œæ¯å‘¨çš„æ–‡ç« æ€»ç»“
"""
from datetime import datetime, timedelta
from typing import List, Dict, Any
from backend.app.db import DatabaseManager
from backend.app.db.models import Article, DailySummary
from backend.app.services.analyzer.ai_analyzer import AIAnalyzer
import logging

logger = logging.getLogger(__name__)


class SummaryGenerator:
    """æ–‡ç« æ€»ç»“ç”Ÿæˆå™¨"""

    def __init__(self, ai_analyzer: AIAnalyzer):
        self.ai_analyzer = ai_analyzer

    def generate_daily_summary(self, db: DatabaseManager, date: datetime = None) -> DailySummary:
        """
        ç”Ÿæˆæ¯æ—¥æ€»ç»“

        Args:
            db: æ•°æ®åº“ç®¡ç†å™¨
            date: æ€»ç»“æ—¥æœŸï¼ˆé»˜è®¤ä»Šå¤©ï¼‰ï¼Œä¼šè®¡ç®—è¯¥æ—¥æœŸå½“å¤©çš„00:00:00è‡³23:59:59

        Returns:
            DailySummaryå¯¹è±¡
        """
        if date is None:
            date = datetime.now()

        # è®¡ç®—è¯¥å¤©çš„èµ·å§‹å’Œç»“æŸæ—¶é—´
        start_date = date.replace(hour=0, minute=0, second=0, microsecond=0)
        end_date = date.replace(hour=23, minute=59, second=59, microsecond=999999)

        logger.info(f"ğŸ“ ç”Ÿæˆæ¯æ—¥æ€»ç»“: {start_date.strftime('%Y-%m-%d %H:%M:%S')} ~ {end_date.strftime('%Y-%m-%d %H:%M:%S')}")

        # ç›´æ¥åœ¨åŒä¸€ä¸ªsessionä¸­å¤„ç†æ‰€æœ‰é€»è¾‘
        return self._create_summary(db, start_date, end_date, "daily", date)

    def generate_weekly_summary(self, db: DatabaseManager, date: datetime = None) -> DailySummary:
        """
        ç”Ÿæˆæ¯å‘¨æ€»ç»“

        Args:
            db: æ•°æ®åº“ç®¡ç†å™¨
            date: æ€»ç»“æ—¥æœŸï¼ˆé»˜è®¤ä»Šå¤©ï¼‰ï¼Œä¼šè®¡ç®—è¯¥æ—¥æœŸæ‰€åœ¨ISOå‘¨çš„å‘¨ä¸€è‡³å‘¨æ—¥

        Returns:
            DailySummaryå¯¹è±¡
        """
        if date is None:
            date = datetime.now()

        # ä½¿ç”¨ISOå‘¨æ ‡å‡†è®¡ç®—è¯¥å‘¨çš„èµ·å§‹æ—¥æœŸï¼ˆå‘¨ä¸€ï¼‰å’Œç»“æŸæ—¥æœŸï¼ˆå‘¨æ—¥ï¼‰
        # ISOå‘¨ï¼šå‘¨ä¸€åˆ°å‘¨æ—¥ï¼Œæ¯å¹´ç¬¬ä¸€å‘¨æ˜¯åŒ…å«1æœˆ4æ—¥çš„é‚£ä¸€å‘¨
        # weekday(): Monday=0, Sunday=6
        days_since_monday = date.weekday()
        start_date = date - timedelta(days=days_since_monday)
        start_date = start_date.replace(hour=0, minute=0, second=0, microsecond=0)
        
        end_date = start_date + timedelta(days=6)
        end_date = end_date.replace(hour=23, minute=59, second=59, microsecond=999999)

        logger.info(f"ğŸ“ ç”Ÿæˆæ¯å‘¨æ€»ç»“: {start_date.strftime('%Y-%m-%d')} ~ {end_date.strftime('%Y-%m-%d')}")

        # ä½¿ç”¨è¯¥å‘¨çš„å‘¨æ—¥ä½œä¸ºsummary_date
        summary_date = end_date

        # ç›´æ¥åœ¨åŒä¸€ä¸ªsessionä¸­å¤„ç†æ‰€æœ‰é€»è¾‘
        return self._create_summary(db, start_date, end_date, "weekly", summary_date)

    def _create_summary(
        self,
        db: DatabaseManager,
        start_date: datetime,
        end_date: datetime,
        summary_type: str,
        date: datetime
    ) -> DailySummary:
        """
        åˆ›å»ºæ€»ç»“

        Args:
            db: æ•°æ®åº“ç®¡ç†å™¨
            start_date: å¼€å§‹æ—¶é—´
            end_date: ç»“æŸæ—¶é—´
            summary_type: æ€»ç»“ç±»å‹ï¼ˆdaily/weeklyï¼‰
            date: æ€»ç»“æ—¥æœŸ

        Returns:
            DailySummaryå¯¹è±¡
        """
        start_time = datetime.now()

        # åœ¨åŒä¸€ä¸ªsessionä¸­æŸ¥è¯¢æ–‡ç« å¹¶æå–æ•°æ®
        with db.get_session() as session:
            # æŸ¥è¯¢å·²åˆ†æçš„æ–‡ç« ï¼ŒæŒ‰é‡è¦æ€§å’Œå‘å¸ƒæ—¶é—´æ’åº
            articles = session.query(Article).filter(
                Article.is_processed == True,
                Article.published_at >= start_date,
                Article.published_at <= end_date
            ).order_by(
                Article.importance.desc(),
                Article.published_at.desc()
            ).all()

            if not articles:
                logger.warning("âš ï¸  æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„æ–‡ç« ")
                return None

            # å‡†å¤‡æ–‡ç« æ•°æ®
            articles_data = []
            for article in articles:
                display_title = article.title_zh if article.title_zh else article.title
                articles_data.append({
                    "id": article.id,
                    "title": display_title,
                    "source": article.source,
                    "importance": article.importance,
                    "published_at": article.published_at,
                    "summary": article.summary,
                    "key_points": article.key_points,
                    "topics": article.topics,
                })

        # ç»Ÿè®¡ä¿¡æ¯
        high_count = sum(1 for a in articles_data if a.get("importance") == "high")
        medium_count = sum(1 for a in articles_data if a.get("importance") == "medium")

        logger.info(f"  æ–‡ç« æ€»æ•°: {len(articles_data)} (é«˜é‡è¦æ€§: {high_count}, ä¸­é‡è¦æ€§: {medium_count})")

        # è°ƒç”¨LLMç”Ÿæˆæ€»ç»“
        prompt = self._build_summary_prompt(articles_data, summary_type, start_date, end_date)
        summary_content = self.ai_analyzer.client.chat.completions.create(
            model=self.ai_analyzer.model,
            messages=[
                {
                    "role": "system",
                    "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIé¢†åŸŸæ–°é—»åˆ†æåŠ©æ‰‹ï¼Œæ“…é•¿ä»å¤§é‡æ–‡ç« ä¸­æç‚¼å…³é”®ä¿¡æ¯å’Œè¶‹åŠ¿ã€‚è¯·ä½¿ç”¨Markdownæ ¼å¼è¾“å‡ºæ‰€æœ‰å†…å®¹ï¼ŒåŒ…æ‹¬æ ‡é¢˜ã€åˆ—è¡¨ã€åŠ ç²—ç­‰Markdownè¯­æ³•ã€‚"
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            temperature=0.3,
            max_tokens=2000
        )
        summary_text = summary_content.choices[0].message.content

        # æå–å…³é”®ä¸»é¢˜
        key_topics = self._extract_topics(articles_data)

        # æ¨èé‡è¦æ–‡ç« 
        recommended_articles = self._select_recommended_articles(articles_data)

        # è®¡ç®—è€—æ—¶
        generation_time = (datetime.now() - start_time).total_seconds()

        # ä¿å­˜åˆ°æ•°æ®åº“ï¼ˆå¦‚æœå·²å­˜åœ¨åˆ™æ›´æ–°ï¼Œå¦åˆ™åˆ›å»ºï¼‰
        with db.get_session() as session:
            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒç±»å‹å’Œæ—¥æœŸçš„æ€»ç»“
            # å¯¹äºdailyç±»å‹ï¼Œæ¯”è¾ƒæ—¥æœŸï¼ˆå¿½ç•¥æ—¶é—´éƒ¨åˆ†ï¼‰
            # å¯¹äºweeklyç±»å‹ï¼Œæ¯”è¾ƒsummary_dateæ‰€åœ¨çš„å‘¨
            existing_summary = None
            if summary_type == "daily":
                # æ¯æ—¥æ€»ç»“ï¼šæ¯”è¾ƒæ—¥æœŸï¼ˆåªæ¯”è¾ƒå¹´æœˆæ—¥ï¼‰
                date_only = date.replace(hour=0, minute=0, second=0, microsecond=0)
                existing_summary = session.query(DailySummary).filter(
                    DailySummary.summary_type == summary_type,
                    DailySummary.summary_date >= date_only,
                    DailySummary.summary_date < date_only + timedelta(days=1)
                ).first()
            else:
                # æ¯å‘¨æ€»ç»“ï¼šæ¯”è¾ƒsummary_dateæ‰€åœ¨çš„å‘¨
                # è®¡ç®—summary_dateæ‰€åœ¨å‘¨çš„å‘¨ä¸€å’Œå‘¨æ—¥
                days_since_monday = date.weekday()
                week_start = date - timedelta(days=days_since_monday)
                week_start = week_start.replace(hour=0, minute=0, second=0, microsecond=0)
                week_end = week_start + timedelta(days=7)
                
                existing_summary = session.query(DailySummary).filter(
                    DailySummary.summary_type == summary_type,
                    DailySummary.summary_date >= week_start,
                    DailySummary.summary_date < week_end
                ).first()
            
            if existing_summary:
                # æ›´æ–°ç°æœ‰æ€»ç»“
                existing_summary.start_date = start_date
                existing_summary.end_date = end_date
                existing_summary.total_articles = len(articles_data)
                existing_summary.high_importance_count = high_count
                existing_summary.medium_importance_count = medium_count
                existing_summary.summary_content = summary_text
                existing_summary.key_topics = key_topics
                existing_summary.recommended_articles = recommended_articles
                existing_summary.model_used = self.ai_analyzer.model
                existing_summary.generation_time = generation_time
                existing_summary.updated_at = datetime.now()
                session.flush()
                summary_id = existing_summary.id
                logger.info(f"âœ… æ€»ç»“å·²æ›´æ–° (ID: {summary_id})")
            else:
                # åˆ›å»ºæ–°æ€»ç»“
                summary = DailySummary(
                    summary_type=summary_type,
                    summary_date=date,
                    start_date=start_date,
                    end_date=end_date,
                    total_articles=len(articles_data),
                    high_importance_count=high_count,
                    medium_importance_count=medium_count,
                    summary_content=summary_text,
                    key_topics=key_topics,
                    recommended_articles=recommended_articles,
                    model_used=self.ai_analyzer.model,
                    generation_time=generation_time
                )
                session.add(summary)
                session.flush()
                summary_id = summary.id
                logger.info(f"âœ… æ€»ç»“å·²ä¿å­˜ (ID: {summary_id})")
            
        # åœ¨sessionå¤–åˆ›å»ºä¸€ä¸ªæ–°çš„å¯¹è±¡è¿”å›ï¼Œé¿å…detached instanceé—®é¢˜
        return DailySummary(
            id=summary_id,
            summary_type=summary_type,
            summary_date=date,
            start_date=start_date,
            end_date=end_date,
            total_articles=len(articles_data),
            high_importance_count=high_count,
            medium_importance_count=medium_count,
            summary_content=summary_text,
            key_topics=key_topics,
            recommended_articles=recommended_articles,
            model_used=self.ai_analyzer.model,
            generation_time=generation_time
        )

    def _build_summary_prompt(
        self, 
        articles_data: List[Dict[str, Any]], 
        summary_type: str,
        start_date: datetime,
        end_date: datetime
    ) -> str:
        """
        æ„å»ºæ€»ç»“æç¤ºè¯

        Args:
            articles_data: æ–‡ç« æ•°æ®åˆ—è¡¨
            summary_type: æ€»ç»“ç±»å‹ï¼ˆdaily/weeklyï¼‰
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ

        Returns:
            æç¤ºè¯å­—ç¬¦ä¸²
        """
        # æ ¹æ®æ—¥æœŸèŒƒå›´ç”Ÿæˆå…·ä½“çš„æ—¶é—´æè¿°
        if summary_type == "daily":
            # æ¯æ—¥æ€»ç»“ï¼šæ˜¾ç¤ºå…·ä½“æ—¥æœŸ
            time_str = start_date.strftime('%Yå¹´%mæœˆ%dæ—¥')
        else:
            # æ¯å‘¨æ€»ç»“ï¼šæ˜¾ç¤ºæ—¥æœŸèŒƒå›´
            time_str = f"{start_date.strftime('%Yå¹´%mæœˆ%dæ—¥')} è‡³ {end_date.strftime('%Yå¹´%mæœˆ%dæ—¥')}"

        # é€‰æ‹©æœ€é‡è¦çš„æ–‡ç« ï¼ˆæœ€å¤š20ç¯‡ï¼‰
        important_articles = articles_data[:20]

        # æ„å»ºæ–‡ç« åˆ—è¡¨
        articles_str = ""
        for i, article in enumerate(important_articles, 1):
            importance_emoji = "ğŸ”´" if article.get("importance") == "high" else "ğŸŸ¡" if article.get("importance") == "medium" else "âšª"
            articles_str += f"""
{i}. {importance_emoji} [{article.get('source', 'Unknown')}] {article.get('title', 'N/A')}
   å‘å¸ƒæ—¶é—´: {article.get('published_at', datetime.now()).strftime('%Y-%m-%d %H:%M')}
   æ‘˜è¦: {article.get('summary', '')[:200]}...
"""

        prompt = f"""è¯·åŸºäº{time_str}æœŸé—´é‡‡é›†çš„ä»¥ä¸‹AIé¢†åŸŸæ–‡ç« ï¼Œç”Ÿæˆä¸€ä»½{time_str}çš„æ–°é—»æ€»ç»“ã€‚

æ–‡ç« åˆ—è¡¨ï¼š
{articles_str}

è¯·ä½¿ç”¨Markdownæ ¼å¼è¾“å‡ºæ€»ç»“ï¼ŒæŒ‰ä»¥ä¸‹æ ¼å¼ï¼š

# ğŸ“Š {time_str}AIæ–°é—»æ€»ç»“

## ğŸ”¥ é‡ç‚¹æ–‡ç« 
åˆ—å‡º3-5ç¯‡æœ€é‡è¦çš„æ–‡ç« ï¼Œæ¯ç¯‡æ–‡ç« æ ¼å¼å¦‚ä¸‹ï¼š
- **æ–‡ç« æ ‡é¢˜ï¼ˆæ¥æºï¼‰**ï¼šç›´æ¥æè¿°æ–‡ç« çš„æ ¸å¿ƒå†…å®¹å’Œé‡è¦æ€§ï¼Œä¸è¦ä½¿ç”¨"æ ¸å¿ƒå†…å®¹"ã€"ä¸ºä»€ä¹ˆé‡è¦"ã€"æ–‡ç« æ ‡é¢˜å’Œæ¥æº"ç­‰ä»»ä½•æ ‡ç­¾æˆ–å­æ ‡é¢˜ï¼Œç›´æ¥è¾“å‡ºå†…å®¹å³å¯ã€‚ä¾‹å¦‚ï¼š
  - **èƒ½æ–‡èƒ½æ­¦!æ™ºå…ƒé¦–ä¸ªæœºå™¨äººè‰ºäººå¤©å›¢äº®ç›¸æ¹–å—å«è§†è·¨å¹´æ¼”å”±ä¼šï¼ˆé‡å­ä½ï¼‰**
    æ™ºå…ƒæœºå™¨äººé¦–æ¬¡åœ¨å¤§å‹ç”µè§†èŠ‚ç›®ä¸­äº®ç›¸ï¼Œå±•ç¤ºäº†AIæœºå™¨äººåœ¨å¨±ä¹é¢†åŸŸçš„åº”ç”¨æ½œåŠ›ï¼Œæ ‡å¿—ç€æœºå™¨äººä»å·¥ä¸šåœºæ™¯å‘æ¶ˆè´¹åœºæ™¯çš„é‡è¦çªç ´ã€‚

## ğŸ“Œ é‡è¦è¶‹åŠ¿
ä»è¿™äº›æ–‡ç« ä¸­æ€»ç»“å‡º2-3ä¸ªé‡è¦è¶‹åŠ¿æˆ–çƒ­ç‚¹è¯é¢˜

## ğŸ¯ æ¨èé˜…è¯»
æ ¹æ®æ–‡ç« çš„å…³è”æ€§å’Œé‡è¦æ€§ï¼Œæ¨è5-10ç¯‡å€¼å¾—æ·±å…¥é˜…è¯»çš„æ–‡ç« 

**é‡è¦æç¤ºï¼šè¯·ç¡®ä¿è¾“å‡ºå†…å®¹ä½¿ç”¨æ ‡å‡†çš„Markdownæ ¼å¼ï¼ŒåŒ…æ‹¬æ ‡é¢˜ï¼ˆ#ã€##ï¼‰ã€åˆ—è¡¨ï¼ˆ-ã€*ï¼‰ã€åŠ ç²—ï¼ˆ**æ–‡æœ¬**ï¼‰ç­‰Markdownè¯­æ³•ã€‚è¯·ç”¨ä¸­æ–‡å›ç­”ï¼Œä¿æŒä¸“ä¸šã€ç®€æ´çš„é£æ ¼ã€‚"""

        return prompt

    def _extract_topics(self, articles_data: List[Dict[str, Any]]) -> List[str]:
        """
        ä»æ–‡ç« ä¸­æå–å…³é”®ä¸»é¢˜

        Args:
            articles_data: æ–‡ç« æ•°æ®åˆ—è¡¨

        Returns:
            ä¸»é¢˜åˆ—è¡¨
        """
        topics_set = set()

        for article in articles_data:
            if article.get("topics"):
                for topic in article.get("topics", []):
                    if topic:
                        topics_set.add(topic)

        return list(topics_set)[:10]  # æœ€å¤šè¿”å›10ä¸ªä¸»é¢˜

    def _select_recommended_articles(self, articles_data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        é€‰æ‹©æ¨èæ–‡ç« 

        Args:
            articles_data: æ–‡ç« æ•°æ®åˆ—è¡¨

        Returns:
            æ¨èæ–‡ç« åˆ—è¡¨
        """
        recommended = []

        # ä¼˜å…ˆé€‰æ‹©é«˜é‡è¦æ€§æ–‡ç« 
        high_importance = [a for a in articles_data if a.get("importance") == "high"]
        medium_importance = [a for a in articles_data if a.get("importance") == "medium"]

        # é€‰æ‹©æœ€å¤š10ç¯‡æ¨èæ–‡ç« 
        selected_articles = (high_importance + medium_importance)[:10]

        for article in selected_articles:
            reason = ""
            if article.get("importance") == "high":
                reason = "é«˜é‡è¦æ€§æ–‡ç« ï¼Œå€¼å¾—é‡ç‚¹å…³æ³¨"
            elif article.get("importance") == "medium":
                reason = "ä¸­ç­‰é‡è¦æ€§ï¼Œå»ºè®®é˜…è¯»"
            if article.get("key_points"):
                reason += f"ã€‚å…³é”®ç‚¹ï¼š{article.get('key_points')[0][:50]}..."

            recommended.append({
                "id": article.get("id"),
                "title": article.get("title"),
                "source": article.get("source"),
                "importance": article.get("importance"),
                "reason": reason
            })

        return recommended
