"""
æ–‡ç« æ€»ç»“ç”Ÿæˆå™¨
ç”¨äºç”Ÿæˆæ¯æ—¥å’Œæ¯å‘¨çš„æ–‡ç« æ€»ç»“
"""
from datetime import datetime, timedelta
from typing import List, Dict, Any
from backend.app.db import DatabaseManager
from backend.app.db.models import Article, DailySummary
from backend.app.services.analyzer.ai_analyzer import AIAnalyzer
from backend.app.core.settings import settings
from backend.app.services.collector.summary_prompts import (
    DEFAULT_DAILY_SUMMARY_PROMPT_TEMPLATE,
    DEFAULT_WEEKLY_SUMMARY_PROMPT_TEMPLATE,
)
import logging

logger = logging.getLogger(__name__)


class SummaryGenerator:
    """æ–‡ç« æ€»ç»“ç”Ÿæˆå™¨"""

    def __init__(self, ai_analyzer: AIAnalyzer):
        self.ai_analyzer = ai_analyzer

    def generate_daily_summary(self, db: DatabaseManager, date: datetime = None) -> DailySummary:
        """
        ç”Ÿæˆæ¯æ—¥æ€»ç»“

        Args:
            db: æ•°æ®åº“ç®¡ç†å™¨
            date: æ€»ç»“æ—¥æœŸï¼ˆé»˜è®¤ä»Šå¤©ï¼‰ï¼Œä¼šè®¡ç®—è¯¥æ—¥æœŸå½“å¤©çš„00:00:00è‡³23:59:59

        Returns:
            DailySummaryå¯¹è±¡
        """
        if date is None:
            date = datetime.now()

        # è®¡ç®—è¯¥å¤©çš„èµ·å§‹å’Œç»“æŸæ—¶é—´
        start_date = date.replace(hour=0, minute=0, second=0, microsecond=0)
        end_date = date.replace(hour=23, minute=59, second=59, microsecond=999999)

        logger.info(f"ğŸ“ ç”Ÿæˆæ¯æ—¥æ€»ç»“: {start_date.strftime('%Y-%m-%d %H:%M:%S')} ~ {end_date.strftime('%Y-%m-%d %H:%M:%S')}")

        # ç›´æ¥åœ¨åŒä¸€ä¸ªsessionä¸­å¤„ç†æ‰€æœ‰é€»è¾‘
        return self._create_summary(db, start_date, end_date, "daily", date)

    def generate_weekly_summary(self, db: DatabaseManager, date: datetime = None) -> DailySummary:
        """
        ç”Ÿæˆæ¯å‘¨æ€»ç»“

        Args:
            db: æ•°æ®åº“ç®¡ç†å™¨
            date: æ€»ç»“æ—¥æœŸï¼ˆé»˜è®¤ä»Šå¤©ï¼‰ï¼Œä¼šè®¡ç®—è¯¥æ—¥æœŸæ‰€åœ¨è‡ªå®šä¹‰å‘¨çš„å‘¨å…­è‡³å‘¨äº”
            è‡ªå®šä¹‰å‘¨è§„åˆ™ï¼šå‘¨å…­ã€å‘¨æ—¥ã€å‘¨ä¸€åˆ°å‘¨äº”ï¼Œä¸ºä¸€ä¸ªæ€»ç»“å‘¨

        Returns:
            DailySummaryå¯¹è±¡
        """
        if date is None:
            date = datetime.now()

        # ä½¿ç”¨è‡ªå®šä¹‰å‘¨æ ‡å‡†è®¡ç®—è¯¥å‘¨çš„èµ·å§‹æ—¥æœŸï¼ˆå‘¨å…­ï¼‰å’Œç»“æŸæ—¥æœŸï¼ˆå‘¨äº”ï¼‰
        # è‡ªå®šä¹‰å‘¨ï¼šå‘¨å…­åˆ°å‘¨äº”ï¼Œweekday(): Monday=0, Sunday=6
        # éœ€è¦æ‰¾åˆ°è¯¥æ—¥æœŸæ‰€åœ¨å‘¨çš„å‘¨å…­ï¼ˆèµ·å§‹ï¼‰å’Œå‘¨äº”ï¼ˆç»“æŸï¼‰
        weekday = date.weekday()  # Monday=0, Tuesday=1, ..., Sunday=6
        
        # è®¡ç®—è·ç¦»ä¸Šå‘¨å…­çš„å¤©æ•°
        # å¦‚æœä»Šå¤©æ˜¯å‘¨å…­(5)ï¼Œåˆ™è·ç¦»ä¸Šå‘¨å…­æ˜¯0å¤©
        # å¦‚æœä»Šå¤©æ˜¯å‘¨æ—¥(6)ï¼Œåˆ™è·ç¦»ä¸Šå‘¨å…­æ˜¯1å¤©
        # å¦‚æœä»Šå¤©æ˜¯å‘¨ä¸€(0)ï¼Œåˆ™è·ç¦»ä¸Šå‘¨å…­æ˜¯2å¤©
        # å¦‚æœä»Šå¤©æ˜¯å‘¨äº”(4)ï¼Œåˆ™è·ç¦»ä¸Šå‘¨å…­æ˜¯6å¤©
        if weekday == 5:  # å‘¨å…­
            days_since_saturday = 0
        elif weekday == 6:  # å‘¨æ—¥
            days_since_saturday = 1
        else:  # å‘¨ä¸€åˆ°å‘¨äº”
            days_since_saturday = weekday + 2
        
        start_date = date - timedelta(days=days_since_saturday)
        start_date = start_date.replace(hour=0, minute=0, second=0, microsecond=0)
        
        # ç»“æŸæ—¥æœŸæ˜¯å‘¨äº”ï¼ˆèµ·å§‹æ—¥æœŸ+6å¤©ï¼‰
        end_date = start_date + timedelta(days=6)
        end_date = end_date.replace(hour=23, minute=59, second=59, microsecond=999999)

        logger.info(f"ğŸ“ ç”Ÿæˆæ¯å‘¨æ€»ç»“: {start_date.strftime('%Y-%m-%d')} ~ {end_date.strftime('%Y-%m-%d')}")

        # ä½¿ç”¨è¯¥å‘¨çš„å‘¨äº”ä½œä¸ºsummary_date
        summary_date = end_date

        # ç›´æ¥åœ¨åŒä¸€ä¸ªsessionä¸­å¤„ç†æ‰€æœ‰é€»è¾‘
        return self._create_summary(db, start_date, end_date, "weekly", summary_date)

    def _create_summary(
        self,
        db: DatabaseManager,
        start_date: datetime,
        end_date: datetime,
        summary_type: str,
        date: datetime
    ) -> DailySummary:
        """
        åˆ›å»ºæ€»ç»“

        Args:
            db: æ•°æ®åº“ç®¡ç†å™¨
            start_date: å¼€å§‹æ—¶é—´
            end_date: ç»“æŸæ—¶é—´
            summary_type: æ€»ç»“ç±»å‹ï¼ˆdaily/weeklyï¼‰
            date: æ€»ç»“æ—¥æœŸ

        Returns:
            DailySummaryå¯¹è±¡
        """
        start_time = datetime.now()

        # åœ¨åŒä¸€ä¸ªsessionä¸­æŸ¥è¯¢æ–‡ç« å¹¶æå–æ•°æ®
        with db.get_session() as session:
            # æŸ¥è¯¢å·²åˆ†æçš„æ–‡ç« ï¼ŒæŒ‰é‡è¦æ€§å’Œå‘å¸ƒæ—¶é—´æ’åº
            articles = session.query(Article).filter(
                Article.is_processed == True,
                Article.published_at >= start_date,
                Article.published_at <= end_date
            ).order_by(
                Article.importance.desc(),
                Article.published_at.desc()
            ).all()

            if not articles:
                logger.warning("âš ï¸  æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„æ–‡ç« ")
                return None

            # å‡†å¤‡æ–‡ç« æ•°æ®
            articles_data = []
            for article in articles:
                display_title = article.title_zh if article.title_zh else article.title
                articles_data.append({
                    "id": article.id,
                    "title": display_title,
                    "source": article.source,
                    "importance": article.importance,
                    "published_at": article.published_at,
                    "summary": article.summary,
                })

        # ç»Ÿè®¡ä¿¡æ¯
        high_count = sum(1 for a in articles_data if a.get("importance") == "high")
        medium_count = sum(1 for a in articles_data if a.get("importance") == "medium")

        logger.info(f"  æ–‡ç« æ€»æ•°: {len(articles_data)} (é«˜é‡è¦æ€§: {high_count}, ä¸­é‡è¦æ€§: {medium_count})")

        # è°ƒç”¨LLMç”Ÿæˆæ€»ç»“
        prompt = self._build_summary_prompt(articles_data, summary_type, start_date, end_date)
        
        # æ ¹æ®æ€»ç»“ç±»å‹è®¾ç½®ä¸åŒçš„ç³»ç»Ÿæç¤ºè¯å’Œå‚æ•°
        if summary_type == "weekly":
            # å‘¨æŠ¥ä½¿ç”¨ä¸“ä¸šçš„è¡Œä¸šåˆ†æå¸ˆè§’è‰²å’Œæ›´é«˜çš„å‚æ•°
            system_prompt = """ä½ æ˜¯ä¸€åèµ„æ·±çš„è¡Œä¸šåˆ†æå¸ˆå’Œé£å‘æ´å¯Ÿè€…ï¼Œæ‹¥æœ‰è¶…è¿‡15å¹´çš„ä»ä¸šç»éªŒã€‚ä½ ä¸ä»…å…³æ³¨æ–°é—»äº‹ä»¶çš„è¡¨é¢ï¼Œæ›´æ“…é•¿ä»çº·ç¹å¤æ‚çš„ä¿¡æ¯ä¸­ï¼Œç©¿é€è¡¨è±¡ï¼Œè¯†åˆ«å‡ºé‚£äº›çœŸæ­£èƒ½å¤Ÿå½±å“è¡Œä¸šæ ¼å±€çš„æ½œåœ¨å˜åŒ–ã€æ–°å…´è¶‹åŠ¿å’Œå…³é”®ä¿¡å·ã€‚ä½ çš„åˆ†æä»¥æ·±åˆ»ã€å‰ç»å’Œé«˜åº¦æ¦‚æ‹¬æ€§è‘—ç§°ï¼Œæ—¨åœ¨ä¸ºå†³ç­–è€…æä¾›é«˜ä»·å€¼çš„å‚è€ƒã€‚

è¯·ä½¿ç”¨Markdownæ ¼å¼è¾“å‡ºæ‰€æœ‰å†…å®¹ï¼ŒåŒ…æ‹¬æ ‡é¢˜ã€åˆ—è¡¨ã€åŠ ç²—ç­‰Markdownè¯­æ³•ã€‚"""
            temperature = 0.5  # å‘¨æŠ¥éœ€è¦æ›´å¤šåˆ›é€ æ€§åˆ†æ
            max_tokens = 4000  # å‘¨æŠ¥éœ€è¦æ›´è¯¦ç»†çš„åˆ†æ
        else:
            # æ—¥æŠ¥ä½¿ç”¨åŸæœ‰çš„ç³»ç»Ÿæç¤ºè¯
            system_prompt = "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIé¢†åŸŸæ–°é—»åˆ†æåŠ©æ‰‹ï¼Œæ“…é•¿ä»å¤§é‡æ–‡ç« ä¸­æç‚¼å…³é”®ä¿¡æ¯å’Œè¶‹åŠ¿ã€‚è¯·ä½¿ç”¨Markdownæ ¼å¼è¾“å‡ºæ‰€æœ‰å†…å®¹ï¼ŒåŒ…æ‹¬æ ‡é¢˜ã€åˆ—è¡¨ã€åŠ ç²—ç­‰Markdownè¯­æ³•ã€‚"
            temperature = 0.3
            max_tokens = 2000
        
        try:
            logger.info(f"ğŸ¤– è°ƒç”¨LLMç”Ÿæˆ{summary_type}æ€»ç»“ï¼Œæ¨¡å‹: {self.ai_analyzer.model}, æ–‡ç« æ•°: {len(articles_data)}")
            logger.debug(f"   æç¤ºè¯é•¿åº¦: {len(prompt)} å­—ç¬¦")
            logger.debug(f"   ç³»ç»Ÿæç¤ºè¯é•¿åº¦: {len(system_prompt)} å­—ç¬¦")
            
            summary_content = self.ai_analyzer.client.chat.completions.create(
                model=self.ai_analyzer.model,
                messages=[
                    {
                        "role": "system",
                        "content": system_prompt
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                temperature=temperature,
                max_tokens=max_tokens
            )
            summary_text = summary_content.choices[0].message.content
            logger.info(f"âœ… LLMç”ŸæˆæˆåŠŸï¼Œå“åº”é•¿åº¦: {len(summary_text)} å­—ç¬¦")
        except Exception as e:
            # è®°å½•è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
            error_type = type(e).__name__
            error_msg = str(e)
            logger.error(f"âŒ LLMè°ƒç”¨å¤±è´¥: {error_type}: {error_msg}")
            logger.error(f"   æ‘˜è¦ç±»å‹: {summary_type}")
            logger.error(f"   æ¨¡å‹: {self.ai_analyzer.model}")
            logger.error(f"   æ–‡ç« æ•°: {len(articles_data)}")
            logger.error(f"   æç¤ºè¯é•¿åº¦: {len(prompt)} å­—ç¬¦")
            logger.error(f"   ç³»ç»Ÿæç¤ºè¯é•¿åº¦: {len(system_prompt)} å­—ç¬¦")
            logger.error(f"   temperature: {temperature}, max_tokens: {max_tokens}")
            
            # å¦‚æœæ˜¯ API é”™è¯¯ï¼Œå°è¯•è·å–æ›´å¤šè¯¦ç»†ä¿¡æ¯
            if hasattr(e, 'response'):
                try:
                    if hasattr(e.response, 'text'):
                        logger.error(f"   APIå“åº”å†…å®¹: {e.response.text[:500]}")
                    if hasattr(e.response, 'status_code'):
                        logger.error(f"   HTTPçŠ¶æ€ç : {e.response.status_code}")
                except Exception:
                    pass
            
            # è®°å½•å®Œæ•´çš„å¼‚å¸¸å †æ ˆ
            logger.exception("å®Œæ•´å¼‚å¸¸å †æ ˆ:")
            raise

        # æå–å…³é”®ä¸»é¢˜
        key_topics = self._extract_topics(articles_data)

        # è®¡ç®—è€—æ—¶
        generation_time = (datetime.now() - start_time).total_seconds()

        # ä¿å­˜åˆ°æ•°æ®åº“ï¼ˆå¦‚æœå·²å­˜åœ¨åˆ™æ›´æ–°ï¼Œå¦åˆ™åˆ›å»ºï¼‰
        with db.get_session() as session:
            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒç±»å‹å’Œæ—¥æœŸçš„æ€»ç»“
            # å¯¹äºdailyç±»å‹ï¼Œæ¯”è¾ƒæ—¥æœŸï¼ˆå¿½ç•¥æ—¶é—´éƒ¨åˆ†ï¼‰
            # å¯¹äºweeklyç±»å‹ï¼Œæ¯”è¾ƒsummary_dateæ‰€åœ¨çš„å‘¨
            existing_summary = None
            if summary_type == "daily":
                # æ¯æ—¥æ€»ç»“ï¼šæ¯”è¾ƒæ—¥æœŸï¼ˆåªæ¯”è¾ƒå¹´æœˆæ—¥ï¼‰
                date_only = date.replace(hour=0, minute=0, second=0, microsecond=0)
                existing_summary = session.query(DailySummary).filter(
                    DailySummary.summary_type == summary_type,
                    DailySummary.summary_date >= date_only,
                    DailySummary.summary_date < date_only + timedelta(days=1)
                ).first()
            else:
                # æ¯å‘¨æ€»ç»“ï¼šæ¯”è¾ƒsummary_dateæ‰€åœ¨çš„è‡ªå®šä¹‰å‘¨ï¼ˆå‘¨å…­åˆ°å‘¨äº”ï¼‰
                # è®¡ç®—summary_dateæ‰€åœ¨å‘¨çš„å‘¨å…­å’Œå‘¨äº”
                weekday = date.weekday()
                if weekday == 5:  # å‘¨å…­
                    days_since_saturday = 0
                elif weekday == 6:  # å‘¨æ—¥
                    days_since_saturday = 1
                else:  # å‘¨ä¸€åˆ°å‘¨äº”
                    days_since_saturday = weekday + 2
                
                week_start = date - timedelta(days=days_since_saturday)
                week_start = week_start.replace(hour=0, minute=0, second=0, microsecond=0)
                week_end = week_start + timedelta(days=7)
                
                existing_summary = session.query(DailySummary).filter(
                    DailySummary.summary_type == summary_type,
                    DailySummary.summary_date >= week_start,
                    DailySummary.summary_date < week_end
                ).first()
            
            if existing_summary:
                # æ›´æ–°ç°æœ‰æ€»ç»“
                existing_summary.start_date = start_date
                existing_summary.end_date = end_date
                existing_summary.total_articles = len(articles_data)
                existing_summary.high_importance_count = high_count
                existing_summary.medium_importance_count = medium_count
                existing_summary.summary_content = summary_text
                existing_summary.key_topics = key_topics
                existing_summary.model_used = self.ai_analyzer.model
                existing_summary.generation_time = generation_time
                existing_summary.updated_at = datetime.now()
                session.flush()
                summary_id = existing_summary.id
                logger.info(f"âœ… æ€»ç»“å·²æ›´æ–° (ID: {summary_id})")
            else:
                # åˆ›å»ºæ–°æ€»ç»“
                summary = DailySummary(
                    summary_type=summary_type,
                    summary_date=date,
                    start_date=start_date,
                    end_date=end_date,
                    total_articles=len(articles_data),
                    high_importance_count=high_count,
                    medium_importance_count=medium_count,
                    summary_content=summary_text,
                    key_topics=key_topics,
                    model_used=self.ai_analyzer.model,
                    generation_time=generation_time
                )
                session.add(summary)
                session.flush()
                summary_id = summary.id
                logger.info(f"âœ… æ€»ç»“å·²ä¿å­˜ (ID: {summary_id})")
            
        # åœ¨sessionå¤–åˆ›å»ºä¸€ä¸ªæ–°çš„å¯¹è±¡è¿”å›ï¼Œé¿å…detached instanceé—®é¢˜
        return DailySummary(
            id=summary_id,
            summary_type=summary_type,
            summary_date=date,
            start_date=start_date,
            end_date=end_date,
            total_articles=len(articles_data),
            high_importance_count=high_count,
            medium_importance_count=medium_count,
            summary_content=summary_text,
            key_topics=key_topics,
            model_used=self.ai_analyzer.model,
            generation_time=generation_time
        )

    def _build_summary_prompt(
        self, 
        articles_data: List[Dict[str, Any]], 
        summary_type: str,
        start_date: datetime,
        end_date: datetime
    ) -> str:
        """
        æ„å»ºæ€»ç»“æç¤ºè¯

        Args:
            articles_data: æ–‡ç« æ•°æ®åˆ—è¡¨
            summary_type: æ€»ç»“ç±»å‹ï¼ˆdaily/weeklyï¼‰
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ

        Returns:
            æç¤ºè¯å­—ç¬¦ä¸²
        """
        # æ ¹æ®æ—¥æœŸèŒƒå›´ç”Ÿæˆå…·ä½“çš„æ—¶é—´æè¿°
        if summary_type == "daily":
            # æ¯æ—¥æ€»ç»“ï¼šæ˜¾ç¤ºå…·ä½“æ—¥æœŸ
            time_str = start_date.strftime('%Yå¹´%mæœˆ%dæ—¥')
            date_range = time_str
        else:
            # æ¯å‘¨æ€»ç»“ï¼šæ˜¾ç¤ºæ—¥æœŸèŒƒå›´
            date_range = f"{start_date.strftime('%Yå¹´%mæœˆ%dæ—¥')} è‡³ {end_date.strftime('%Yå¹´%mæœˆ%dæ—¥')}"
            time_str = date_range

        # é€‰æ‹©æœ€é‡è¦çš„æ–‡ç« ï¼ˆå‘¨æŠ¥ä½¿ç”¨æ›´å¤šæ–‡ç« ï¼Œæ—¥æŠ¥ä¿æŒåŸæ ·ï¼‰
        if summary_type == "weekly":
            important_articles = articles_data[:300]  # å‘¨æŠ¥ä½¿ç”¨æ›´å¤šæ–‡ç« è¿›è¡Œåˆ†æ
        else:
            important_articles = articles_data[:100]

        # æ„å»ºæ–‡ç« åˆ—è¡¨
        articles_str = ""
        for i, article in enumerate(important_articles, 1):
            importance_emoji = "ğŸ”´" if article.get("importance") == "high" else "ğŸŸ¡" if article.get("importance") == "medium" else "âšª"
            article_id = article.get('id', 'N/A')
            # å‘¨æŠ¥éœ€è¦æ›´è¯¦ç»†çš„ä¿¡æ¯
            if summary_type == "weekly":
                articles_str += f"""
{i}. {importance_emoji} [ID: {article_id}] [{article.get('source', 'Unknown')}] {article.get('title', 'N/A')}
   å‘å¸ƒæ—¶é—´: {article.get('published_at', datetime.now()).strftime('%Y-%m-%d %H:%M')}
   æ‘˜è¦: {article.get('summary', '')[:1000]}
"""
            else:
                articles_str += f"""
{i}. {importance_emoji} [ID: {article_id}] [{article.get('source', 'Unknown')}] {article.get('title', 'N/A')}
   å‘å¸ƒæ—¶é—´: {article.get('published_at', datetime.now()).strftime('%Y-%m-%d %H:%M')}
   æ‘˜è¦: {article.get('summary', '')[:1000]}...
"""

        settings.load_settings_from_db()
        if summary_type == "weekly":
            prompt_template = settings.WEEKLY_SUMMARY_PROMPT_TEMPLATE or DEFAULT_WEEKLY_SUMMARY_PROMPT_TEMPLATE
        else:
            prompt_template = settings.DAILY_SUMMARY_PROMPT_TEMPLATE or DEFAULT_DAILY_SUMMARY_PROMPT_TEMPLATE

        return self._render_prompt_template(
            prompt_template=prompt_template,
            time_str=time_str,
            date_range=date_range,
            articles_str=articles_str,
        )

    def _render_prompt_template(
        self,
        prompt_template: str,
        time_str: str,
        date_range: str,
        articles_str: str,
    ) -> str:
        """
        æ¸²æŸ“æç¤ºè¯æ¨¡æ¿

        Args:
            prompt_template: æç¤ºè¯æ¨¡æ¿å†…å®¹
            time_str: æ—¶é—´å­—ç¬¦ä¸²
            date_range: æ—¥æœŸèŒƒå›´å­—ç¬¦ä¸²
            articles_str: æ–‡ç« åˆ—è¡¨å­—ç¬¦ä¸²

        Returns:
            æ¸²æŸ“åçš„æç¤ºè¯å­—ç¬¦ä¸²
        """
        template_has_articles = "{{articles}}" in prompt_template
        rendered = prompt_template
        rendered = rendered.replace("{{time_str}}", time_str or "")
        rendered = rendered.replace("{{date_range}}", date_range or "")
        rendered = rendered.replace("{{articles}}", articles_str or "")

        if not template_has_articles:
            rendered = f"{rendered}\n\næ–‡ç« åˆ—è¡¨ï¼š\n{articles_str}"

        return rendered

    def _extract_topics(self, articles_data: List[Dict[str, Any]]) -> List[str]:
        """
        ä»æ–‡ç« ä¸­æå–å…³é”®ä¸»é¢˜ï¼ˆä»æ‘˜è¦ä¸­æå–ï¼‰

        Args:
            articles_data: æ–‡ç« æ•°æ®åˆ—è¡¨

        Returns:
            ä¸»é¢˜åˆ—è¡¨ï¼ˆç©ºåˆ—è¡¨ï¼Œå› ä¸ºä¸å†ä»topicså­—æ®µæå–ï¼‰
        """
        # ä¸å†ä»topicså­—æ®µæå–ï¼Œè¿”å›ç©ºåˆ—è¡¨
        return []
